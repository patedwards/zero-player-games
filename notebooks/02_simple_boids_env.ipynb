{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab18d3f7-fd86-4c67-bbbf-3d97072695d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "source": [
    "```\n",
    "!pip3.10 install swig\n",
    "!pip3.10 install gym[box2d]\n",
    "!pip3.10 install imageio imageio[ffmpeg]\n",
    "!pip3.10 install stable-baselines3[extra]\n",
    "!pip3.10 install -e ../\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add4a428-26d4-46d9-9122-061eee0d5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from IPython.display import Video\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\" # this stops pygame opening it's own window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ee2688-5249-494d-a846-cfa7804ca475",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcc665a-0982-4d94-a91e-8d8975a4ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from environments.model_ready_boids import RavenChasingBoids\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58380428-c5fc-4b69-963f-4c478f567faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "# Now import the function\n",
    "import gym_utils\n",
    "import controllers\n",
    "import agents\n",
    "import runners\n",
    "import environments\n",
    "from environments.simple_boids import PureBoinds, BoidsWithRavenoid\n",
    "from gym_utils.vis import create_environment_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d79cacb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e66d6f-8048-4ab2-ac7e-0b7359c69f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa0945-2f73-4def-a9a4-fe42e56bf883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = PureBoinds(100, render_mode=\"rgb_array\")\n",
    "\n",
    "\n",
    "# Create a video\n",
    "video_filename = 'boids.mp4'\n",
    "create_environment_video(env, video_filename, steps=200)\n",
    "\n",
    "# Display the video\n",
    "Video(video_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bd3d44b-73d3-43fe-b828-ab7eafad87e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"boids.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = BoidsWithRavenoid(100, render_mode=\"rgb_array\")\n",
    "\n",
    "\n",
    "# Create a video\n",
    "video_filename = 'boids.mp4'\n",
    "create_environment_video(env, video_filename, steps=200)\n",
    "\n",
    "# Display the video\n",
    "Video(video_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd48c1d2-7d9e-4e6b-835b-8e39736138d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0 steps taken. Average steps per episode: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/patrick/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"mock_boids.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from environments.model_ready_boids import RavenChasingBoids\n",
    "\n",
    "class AlternatingActionModel:\n",
    "    def __init__(self, env):\n",
    "        self.action_space = env.action_space\n",
    "        self.step_count = 0\n",
    "        self.env = env\n",
    "\n",
    "    def predict(self, observation, state=None, episode_start=None, deterministic=None):\n",
    "        # Define the policy: alternate between action 1 and action 2 every 4 steps\n",
    "        action_period = 4\n",
    "        if (self.step_count // action_period) % 2 == 0:\n",
    "            action = 1  # Use action 1 for 4 steps\n",
    "        else:\n",
    "            action = 2  # Then switch to action 2 for the next 4 steps\n",
    "\n",
    "        self.step_count += 1\n",
    "        return action, state\n",
    "\n",
    "    def get_env(self): return self.env\n",
    "        \n",
    "env = RavenChasingBoids(10, render_mode=\"rgb_array\")\n",
    "print(env.history)\n",
    "model = AlternatingActionModel(env)\n",
    "\n",
    "from gym_utils.vis import create_environment_video_with_model\n",
    "\n",
    "video_filename = 'mock_boids.mp4'\n",
    "create_environment_video_with_model(model, video_filename, steps=1000)\n",
    "print(env.history)\n",
    "Video(video_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c85d08b-89a2-4dce-84fe-e11d74d06347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f12174-8c14-46fc-a95a-6240a80ad508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAEAAQADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPYPHfjvwNrfwv0jRtG0TyNQhx5UOCP7NwRv8Anx+838/72dzYYAV4/RRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUVqeHNAvvFPiCz0XTVjN3dOVTzG2qoALMxPoFBPGTxwCeK6D4jfDm++HmqW0E91HeWd2ha2uVXYXK43qyZJUgsO5BBHOcgAHF0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFWL6wvNMvJLO/tJ7S6jxvhnjMbrkAjKnkZBB/Gq9ABRRRQAUUUUAFFFbGoeFdd0rQ7DWr7TJ4NN1DP2adwMP3GR1XI5GcbgMjI5oAx6K9Y/4VBZ/8Ke/4TD+34Pt3lfa9u8fZ/L6eTnGfOzx6b/kx/FXk9AEkE81rcRXFvLJDPE4eOSNirIwOQQRyCDzmtDX/Eer+KdUbUtavpLu7KBN7AKFUdAqqAFHU4AHJJ6k1l0UAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFdB4H16z8MeNNL1m/svttraS73hABPIIDLnjcpIYdOVHI6jn6KAPUPjX450Lxprmn/2HF5kdlEyPfmMoZ92CFAIDbUwcZ7s2BjlvL6KKACiiigAooooA2NB8K674n+2f2Lpk979ji86fygPlXsOerHBwoyxwcA4NfR/w+8daX8SvA2oaZ4tNi11bREX8crbFlgAB+0dgmD1Kn5WUN8uVA4D9n7xp/ZWuT+Gb67ghsL/ADLbCRcE3XyqFDf7SjoepVQME4btx8EvCfiDxbrOtza3PqEMmoM8lpbSoBDLu3SxSMuSeT0GxlBxknmgDgP+FO6x/wAIN/aX/CTf8SD7X9t8nY+z7HjH2zy92PM8v5/Lxu28bt3y1X+L/gnwd4V07RJvDuo5uriJd1v5vnfaIsEi53DhcnjjCtn5QNrZ3J/DkOqfEGX4YaP4wkj8KI5vJ7IuC0UinL20bnJcg/NgkhfmJDOhz5v8RvCEPgfxjcaPb6hHeQBFljIYGSNWzhJAOA4HPuCrYGcAA5OiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKsQ395b2dzZw3c8drdbftEKSEJLtOV3KOGweRnpVeigCSCea1uIri3lkhnicPHJGxVkYHIII5BB5zRPPNdXEtxcSyTTyuXkkkYszsTkkk8kk85qOigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigBVG5gMgZOMnpVi6tRAqkPnPBB61WpSxbGSTgYGa66VWhGhOE4Xk7Wd9u+hLTummJRRRXIUFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXpHwa/wCEK/4Sif8A4S/yN3lf6F9t2/ZN2Dv8zdxuxjbu+Xr/ABba83r6L+HN54A8cfD638CXFpHZ6gUZ5IDxJJMoGbmOQjBcjnHUAMuCg5APDPFX9hf8JRqP/CNef/Y3mn7L5+d23HOM87c527vm24zzmseus+I3hCHwP4xuNHt9QjvIAiyxkMDJGrZwkgHAcDn3BVsDOBydABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFSQTzWtxFcW8skM8Th45I2KsjA5BBHIIPOajooAknnmuriW4uJZJp5XLySSMWZ2JySSeSSec1HRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUVq2Wg3N7p7XSMo/55of48dee3+elZVRGpGTaT2Oitha1GEJ1I2U1dea/r9H1CiiirOcKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDT0zWptMiliWNZEflQeNrevuPb+VZ0kjzSvK5y7sWY+pNNoqFTipOSWrOipiq1SlGjOV4x2XYKKKKs5wooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA//Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "env = RavenChasingBoids(20, render_mode=\"rgb_array\")\n",
    "env.step(0)\n",
    "for i in range(1000):\n",
    "    env.step(0)\n",
    "arr = env.render()\n",
    "Image.fromarray(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a9ec654-82ae-48bc-9baa-47a2e1d5a147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABgAGADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD5/ooooAKKKKACiiigAooooAKK9Y+A2jeFtZ8UXkevpBc3yRA2FncgNHLw3mHaRhmUbcA9ixwduV4fxxa6FY+NNUtvDVx5+kRy4t3Dlx0G4Kx+8obcAecgA5PUgHP0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUU+ONpXCIMn+VXTpyqSUIK7eyBuwyinyRtE5Rxg/zplFSnKnJwmrNboE7hRRRUAFFFFABRRRQAUUUUAFPjkaJw6HB/nTKKunUlTkpwdmtmDVx8kjSuXc5P8AKmUUUVKkqknObu3uwSsFFFFQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAABgCAIAAABt+uBvAAABA0lEQVR4Ae3aQQrDIBAAQO3//9xKWyQ1IZBUZNHx5Gqi7oCeNiWNAAECBAgQIECAwBoCz3frleuj10JB1ik4n5PUzp8HmwqoQWnCe1JTAd0jOP8L0LlPmgoo57xNtwm3U0v3y9PT5fVZGlHyBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAIFjgVJA962hO54fPhqqPqjS1M5wj92GcYAalCbcHXzUQBygURlf3CcO0E/1XEpNeDGteT8vNyvK5ZoXWWYECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQJBBV6U0B/7WM5IbgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x96>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(env._get_obs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1aa2a81-ab33-4780-8339-7a2da84ea5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 steps taken. Average steps per episode: nan\n",
      "0 steps taken. Average steps per episode: nan\n",
      "1 steps taken. Average steps per episode: nan\n"
     ]
    }
   ],
   "source": [
    "from environments.model_ready_boids import RavenChasingBoids\n",
    "\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "env = RavenChasingBoids(20, render_mode=\"rgb_array\")\n",
    "check_env(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07246e-82fc-4664-a7c4-736ecaf5154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wow, that passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94b24f91-7cc5-4f12-bc20-b6ff993c6e15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "0 steps taken. Average steps per episode: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:231: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 55.31GB > 4.70GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895 steps taken. Average steps per episode: 895.0\n",
      "1001 steps taken. Average steps per episode: 948.0\n",
      "1001 steps taken. Average steps per episode: 965.6666666666666\n",
      "1001 steps taken. Average steps per episode: 974.5\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 974      |\n",
      "|    ep_rew_mean      | 1.5      |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 248      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 3898     |\n",
      "----------------------------------\n",
      "1001 steps taken. Average steps per episode: 979.8\n",
      "616 steps taken. Average steps per episode: 919.1666666666666\n",
      "550 steps taken. Average steps per episode: 866.4285714285714\n",
      "1001 steps taken. Average steps per episode: 883.25\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 883      |\n",
      "|    ep_rew_mean      | 1.88     |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 251      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 7066     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m DQN(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Train the agent and display a progress bar\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2e6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/dqn/dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[1;32m    260\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:312\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    309\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 312\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:544\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    541\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    547\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_transpose.py:95\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m---> 95\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/src/environments/model_ready_boids.py:116\u001b[0m, in \u001b[0;36mRavenChasingBoids.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_frame()\n\u001b[0;32m--> 116\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mravenoid\u001b[38;5;241m.\u001b[39mkill_count\n\u001b[1;32m    118\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/src/environments/model_ready_boids.py:83\u001b[0m, in \u001b[0;36mRavenChasingBoids._get_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m center \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mravenoid\u001b[38;5;241m.\u001b[39mposition)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     78\u001b[0m color_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboid\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m),\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravenoid\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m),\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdead\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, ), \u001b[38;5;66;03m# make the dead boids black as they are invisible to the Ravenoid\u001b[39;00m\n\u001b[1;32m     82\u001b[0m }\n\u001b[0;32m---> 83\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuman_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuman_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecenter_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frame\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/src/visualization/vis.py:64\u001b[0m, in \u001b[0;36mVis.draw_agents\u001b[0;34m(self, agents, human_mode, crop_size, recenter_position, color_map)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclock\u001b[38;5;241m.\u001b[39mtick(\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Capture the screen surface and convert it to a numpy array\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m frame \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurfarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray3d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscreen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Transpose the array to get it in the HxWxC format\u001b[39;00m\n\u001b[1;32m     66\u001b[0m frame \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(frame, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/pygame/surfarray.py:192\u001b[0m, in \u001b[0;36marray3d\u001b[0;34m(surface)\u001b[0m\n\u001b[1;32m    190\u001b[0m width, height \u001b[38;5;241m=\u001b[39m surface\u001b[38;5;241m.\u001b[39mget_size()\n\u001b[1;32m    191\u001b[0m array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mempty((width, height, \u001b[38;5;241m3\u001b[39m), numpy\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m--> 192\u001b[0m \u001b[43msurface_to_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurface\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create environment\n",
    "env = RavenChasingBoids(20, render_mode=\"rgb_array\")\n",
    "\n",
    "# Instantiate the agent\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "# Train the agent and display a progress bar\n",
    "model.learn(total_timesteps=int(2e6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b955a31-363d-4e20-8d7d-a6453a660f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">   0%</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">9,020/2,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:01:32</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">6:06:56</span> , <span style=\"color: #800000; text-decoration-color: #800000\">90 it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m   0%\u001b[0m \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9,020/2,000,000 \u001b[0m [ \u001b[33m0:01:32\u001b[0m < \u001b[36m6:06:56\u001b[0m , \u001b[31m90 it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9beb3b7-76b3-4091-931a-a0f1ae08bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ravenoid_200k_its\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "100d31ef-01cc-4cbd-81dd-6ed4d4730edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "391 steps taken. Average steps per episode: 749.7912087912088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:231: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 55.31GB > 5.36GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001 steps taken. Average steps per episode: 750.7080291970802\n",
      "639 steps taken. Average steps per episode: 750.3018181818181\n",
      "1001 steps taken. Average steps per episode: 751.2101449275362\n",
      "1001 steps taken. Average steps per episode: 752.1119133574007\n",
      "822 steps taken. Average steps per episode: 752.363309352518\n",
      "1001 steps taken. Average steps per episode: 753.2544802867384\n",
      "1001 steps taken. Average steps per episode: 754.1392857142857\n",
      "352 steps taken. Average steps per episode: 752.7081850533808\n",
      "1001 steps taken. Average steps per episode: 753.5886524822695\n",
      "397 steps taken. Average steps per episode: 752.3286219081272\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(\"ravenoid_200k_its\", env=env)\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "982b3e79-edea-4e15-84cc-065c5a01d840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6 1.2806248474865698\n"
     ]
    }
   ],
   "source": [
    "print(mean_reward, std_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4add796-f5e9-4d47-83b4-1a1a029fcf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "0 steps taken. Average steps per episode: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/Projects/active_projects/zero-player-games/zero-player-games/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:231: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 55.31GB > 4.87GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475 steps taken. Average steps per episode: 475.0\n"
     ]
    }
   ],
   "source": [
    "env = RavenChasingBoids(20, render_mode=\"rgb_array\")\n",
    "model = DQN.load(\"ravenoid_200k_its\", env=env)\n",
    "\n",
    "video_filename = 'ravenoid.mp4'\n",
    "create_environment_video_with_model(model, video_filename, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "679604e2-9ca5-4f30-9e27-38524a170a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"ravenoid.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(video_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c38082-716e-46b0-bc35-7be15fa13414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_utils.vis import create_environment_video_with_model\n",
    "from stable_baselines3 import DQN\n",
    "from environments.model_ready_boids import RavenChasingBoids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65761c96-4a1e-4989-813a-0725deb4699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RavenChasingBoids(20, render_mode=\"rgb_array\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d264d90-4a18-4c66-a5bf-d1cacc7dc158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.n_boids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b733f-1281-4979-93bd-12b0c3637c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero-player-games",
   "language": "python",
   "name": "zero-player-games"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
